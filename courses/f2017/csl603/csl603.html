<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>f17csl603</title>

<link href="../../../css/layout.css" rel="stylesheet" type="text/css" />
<style type="text/css">
.holiday {
	color: #808080;
}
</style>
</head>

<body><div id="wrapper">

  <div id="pre-header">
	</div>

  <div id="header">

</div>

<div id="content">


<a name="top"></a>
<h1 align="center">CSL 603 - Machine Learning- Fall 2017</h1>
<p align="center">&nbsp;</p>
<div align="center">
<table width="600" border="0" align="center">
  <tr>
    <th width="150" scope="col"><em><a href="#courseinfo"> Course Information </a></em></th>
    <th width="150" scope="col"><em><a href ="#grading">Grading Policy</a></em></th>
    <th width="150" scope="col"><em><a href="#lectures">Lectures/Calendar</a></em></th>
    <th width="150" scope="col"><em><a href="#labs">Labs</a></em></th>
    </tr>
</table>
</div>
<p align="center">&nbsp;</p>

<a name="courseinfo"></a>
<section title="Course Information">
<h2 align="left"> Course Information </h2>
<p>&nbsp;</p>

<h3 align="left" class="heading3">Timings and Lecture Hall </h3>
<p><strong>Monday - 11.45am-12.35pm <br />
   Tuesday - 9.00-9.50am <br />
   Wednesday - 9.55-10.45am</strong></p>
<p><strong>Transit Campus II - Lecture Room H8</strong></p>
<p><strong>Lab hours: Friday 9.00am-10.35am</strong></p>
<h3 align="left" class="heading3">&nbsp; </h3>
<h3 align="left" class="heading3">Description </h3>
<p align="justify">Machine Learning (ML) is the study of computer algorthms that learn and imrpove automatically through experience. ML is an increasingly popular subject due to a wide variety of applications such as autonomous vehicles, hand-written character recognition, automatic speech processing, recommendation systems, etc. This introductory (undergraduate-graduate bridge) course discusses some of the basic and widely used ML techniques, covering a wide range of topics such as  supervised and unsupervised learning, classification and regression, artificial neural networks, and dimensionality reduction. For a comprehensive list of topics covered in the course and course schedule, please see the course calendar. Practical experience will be gained through implementing the ML algorithms for different applications in Python/C/C++. For more details on lab assignments, please see the Labs webpage. This course has a pre-requisite of CSL201 (Data Structures). Background in Linear Algebra, Probability and Statistics, and Optimization will be helpful, though not necessary.</p>
<p>&nbsp;</p>


<h3 align="left" class="heading3">Reference Material </h3>
<p> There is no fixed textbook for the course. However content will be adopted from the following textbooks</p>
<ul> 
<li><a href="http://www.cs.cmu.edu/~tom/mlbook.html">Machine Learning</a> by Tom Mitchell (ML)</li>
<li><a href="https://mitpress.mit.edu/books/introduction-machine-learning">Introduction to Machine Learning</a> by Ethem Alpaydin (IML)</li>
<li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">Elements of Statistical Learning </a> by Trevor Hastie, Robert Tibshirani and Jerome Friedman (available online for free) (ESL)</li>
<li><a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/">Pattern Recognition and Machine Learning </a> by Christopher Bishop (PRML)</li>
</ul>
</p>
<p>&nbsp;</p>

<h3 align="left" class="heading3">Instructor Details</h3> 
<p><strong>Narayanan (CK) Chatapuram Krishnan</strong></p>
<p><strong>Office Hours:</strong> 11.00am-12.00pm</p>
<p><strong>Office:</strong> 318</p>
<p><strong>Phone:</strong> +91 1881 242273</p>
<p><strong>Email:</strong> ckn@iitrpr.ac.in</p>
<p>&nbsp;</p>

<h3 align="left" class="heading3">Teaching Assistants Details</h3> 
<p><strong>Sanatan Sukhija</strong></p>
<p><strong>Office:</strong> 120</p>
<p><strong>Office hours: Wednesday all day (with prior appointment)</strong></p>
<p><strong>Email:</strong> sanatan@iitrpr.ac.in</p>
<p><strong>Akanksha Paul</strong></p>
<p><strong>Office:</strong> 237</p>
<p><strong>Office hours: Monday after class</strong></p>
<p><strong>Email:</strong> akanksha.paul@iitrpr.ac.in</p>
<p>&nbsp;</p>

<h3 align="left" class="heading3"> Academic Integrity </h3>
<p align="justify">It is expected that students who are taking this course will demonstrate a keen interest in learning and not mere fulfilling the requirement towards their degree. Discussions that help the student understand a concept or a problem is encouraged. However, each student must turn in original work. Plagiarism/copying of any form, will be dealt with strict disciplinary action. This involves, copying from the internet, textbooks and any other material for which you do not own the copyright. Copying part of the code will be considered plagiarism. Lending the code to others will be considered plagiarism too, for it is difficult to investigate who copied whose code. <strong>Students who violate this policy will  directly receive a failing grade in the course.</strong> <strong>Remember - Your partial submission can fetch you some points, but submitting other's work as your own can result in you failing the course</strong>.  Please talk to the instructor if you have questions about this policy. All academic integrity issues will be handled in accordance with institute regulations.</p>
<p>&nbsp;</p>

<div align="right"> 
<a href="#top">Scroll to top </a>
<hr width="50%" />
</div>
</section>

<a name="grading"></a>
<section title="Grading">
<h2 align="left"> Grading Policy </h2>
<p>&nbsp;</p>

<h3 class="heading3"> Grading Policy </h3>
<p> 
<strong>Quizzes:</strong> There will be approximately 4 pre-announced quizzes during the semester. Check the course calendar to learn about dates on which a quiz will be held. All the quiz scores will count towards the student's overall grade. The quizzes will account for 20% of the overall grade.</p>
<p>&nbsp;</p>
<p>
<strong> Labs:</strong> There will be 4 labs. Each lab will have a major programming component and will span for approximately two-three weeks. All the 4 labs will account for 20% of the overall grade. Students having difficulty with the labs are encouraged to contact the TA for assistance.
You are not required to be physically present in the lab during the lab hours. You can complete the labs at your convenience and turn it in by the deadline. There will be penalty for late submission of the labs. It will start at 1% for the first hour after the submission deadline and increase exponentially for every hour hence forth.</p>
<p>&nbsp;</p>
<p><strong>Project:</strong> There will be a course project worth 10% of the overall grade. This will be a group project. The details of the project will be announced as the semester progresses.</p>
<p>&nbsp;</p>
<p>
<strong> Exams:</strong> The mid and end semester exams together will account for 50% (25% each) of the overall grade.
</p>
<p>&nbsp;</p>
<p><strong>Attendance: </strong>There is no mandatory attendance. However attendance will be taken in every class. This will consitute a bonus of 1% for the final grade and might be helpful for all border line students.</p>
<p>&nbsp;</p>
<p><strong>Passing Critera:</strong> A student must secure an overall score of 40 (out of 100) and a combined score of 60 (out of 200) in the exams to pass the course.</p>
<p>&nbsp;</p>

<h3 class="heading3"> Tentative Grade Breakup* </h3>
<table width="232" border="1">
  <tr>
    <th width="176" scope="row">Quizzes (4)</th>
    <td width="40">20%</td>
  </tr>
  <tr>
    <th scope="row">Labs (4)</th>
    <td>20%</td>
  </tr>
    <tr>
    <th scope="row">Project</th>
    <td>10%</td>
  </tr>
  <tr>
    <th scope="row">Mid-Semester Exam</th>
    <td>25%</td>
  </tr>
    <tr>
    <th scope="row">End-Semester Exam</th>
    <td>25%</td>
  </tr>
    <tr>
    <th scope="row">Total</th>
    <td>100</td>
  </tr>
</table>
<p>*This is a tentative breakup of the grades and can change at the discretion of the instructor. However, any change with respect to the grade break-up will be intimated in advance.</p>
<p>&nbsp;</p>
<p><strong>Grade Sheet:</strong><a href="grades.pdf">PDF</a></p>

<div align="right"> 
<a href="#top">Scroll to top </a>
<hr width="50%" />
</div>
</section>

<a name="lectures"></a>
<section title="Lectures and Calendar">
<h2 align="left"> Lectures and Calendar </h2>
<p align="left">&nbsp;</p>
<h3 class="heading3">Tentative Schedule and List of Topics*</h3>
<div  align="center">
<table width="900" border="1">
  <tr>
    <th width="200" scope="col">Week</th>
    <th width="650" scope="col">Topic and Readings</th>
    <th width="100" scope="col"><div align="center">Quiz/Lab</div></th>
  </tr>
  <tr>
    <th scope="row">1 (Aug7-Aug11)</th>
    <td><a href="w1.pdf">Introduction and Supervised Learning</a><br />
   		Readings:
        <ul>
        <li><p>Chapter 1 (ML)</p></li>
        <li><p>Chapter 1 and 2(IML)</p></li>
        </ul>
        Scribes: <a href="w1n.pdf">Aditya Ranjan, Manish Kumar, Pratham Gupta, Rohit</a></td>
    <td><div align="center"></div></td>
  </tr>
  <tr>
   <th scope="row">2 (Aug14-Aug18)</th>
    <td><a href="w2.pdf">Decision Tree Learning</a><br />
   		Readings:
        <ul>
        <li><p>Chapter 3 (ML)</p></li>
        </ul>
        Other Reference Material: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/decisionForests_MSR_TR_2011_114.pdf">Decision Forests for Classification</a> by Criminisi et al. 2011 (refer Chapters 1-3) <br />
        Scribes: Katta Sai Srinadhu, Sarthak Gupta, Vinit Jagdish Kothawade	 	
    </td>
    <td><div align="center">T1</div></td>
  </tr>
  <tr>
    <th scope="row">3 (Aug21-Aug25)</th>
    <td><a href="w3.pdf">Linear Regression</a><br />
   		Readings:
        <ul>
        <li><p><a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf">Notes</a> by Andrew Ng (Part I - 1-5)</p></li>
        <li>
          <p>Chapter 3 (ESL) (for Regularization and LASSO)</p></li>
        <li>
          <p>Chapter 3 - 3.1-3.2 (PRML) (for Bias-Variance Analysis)</p></li>
        </ul> 	
    	Other Reference Material: <a href="http://cs229.stanford.edu/section/cs229-linalg.pdf">Matrix and Vector Algebra Review</a><br />
        Scribes: Allu Krishna Sai Teja, Katyayani Jaiswal, Koustav Das, Vishal Singh 	 	
    </td>
    <td><div align="center"><a href="q1.pdf">Q1</a></div></td>
  </tr>
  <tr>
   <th scope="row">4 (Aug28-Sep1)</th>
    <td><a href="w4.pdf">Linear Classification</a><br />
   		Readings:
        <ul>
        <li>
          <p>Chapter 4 - 4.1-4.3 (ESL) (for Classification through Linear Regression, Linear Discriminants and Logistic Regression)</p></li>
        <li>
          <p><a href="cs229-notes1.pdf">Notes</a> by Andrew Ng (Part II) (for Logistic Regression and Netwon Raphson Method)</p></li>
        </ul> 	
    	Other Reference Material: <a href="https://tminka.github.io/papers/logreg/minka-logreg.pdf">Optimizers for Logistic Regression</a><br />
        Scribes: Eswar Dev Harsha, Gaurav Kumar, Rajat Sharma, Thota Venkata Sainath	 	
    </td>
    <td><div align="center"><a href="l1.pdf">L1 (Sep 4)</a></div></td>
  </tr>
  <tr>
    <th scope="row">5 (Sep4-Sep8)</th>
    <td rowspan="2"><a href="w5-6.pdf">Artificial Neural Networks</a><br />
   		Readings:
        <ul>
        <li> Chapter 4 (ML) (for basic perceptron, mlp, and back propagation)</li>
        <li> Chapter 5 - 5.1, 5.5.1-5.5.3 (PRML) (for weight space symmetries and regularization)</li>
		<li> Dropout - <a href="http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf">Srivastava et. al., 2014</a> </li>
        <li>Batch Normalization - <a href="https://arxiv.org/pdf/1502.03167.pdf">Ioffe and Szegedy 2015</a></li>
        <li><a href="http://cs231n.github.io/neural-networks-2/">Training and Tuning a CNN</a></li>
        </ul>
     	Other Reference Material:
        <ul>        
        <li>ImageNet Classification with Deep CNN (Alex Net), <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">Krizhevsky et. al., 2012</a></li>
        <li><a href="http://www.deeplearningbook.org/">Deep learning book</a>(Computational Graph, Recurrent Network)</li>
        </ul>
        Scribes: (week 5) Alok Kiran, B Yugandhar, Eeshan Sharma, Narotam Singh <br />
        Scribes: (week 6) Love Mehta, Nikhil Kumar, Nittin Singh, Sujit Rai 	 	
    </td>
    <td><div align="center"><a href="t2.pdf">T2</a></div></td>
  </tr>
  <tr>
     <th scope="row">6 (Sep11-Sep15)</th>
    <td><div align="center"><a href="q2.pdf">Q2</a></div></td>
  </tr>
  <tr>
    <th scope="row">7 (Sep18-Sep22)</th>
    <td><a href="w7.pdf">Experimental Design</a><br />
   		Readings:
        <ul>
        <li> Chapter 4 (ML) (for interval estimation and hypothesis testing) </li>
        <li> Chapter 19.6-19.11 (IML) (for measures of performance, design of experiments, and hypothesis testing)
        </li>
        </ul>
     	Other Reference Material: <br />
        Scribes: Anirudh Sharma, Chaudhari Milan Jayeshbhai, Harshita Modi, Kartik Vishwakarma	 	
    </td>
    <td><div align="center"><a href="l2.zip">L2 (Sep 22)</a> </div></td>
  </tr>
  <tr>
    <th scope="row">8 (Sep25-Sep29)</th>
    <td>Reserve Week<br />
   		Readings: <br />
     	Other Reference Material: <br />
        Scribes: Jatin Goyal, Pratibha Kumari, Sachin Bijalwan, Shreya Dubey</td>
    <td><div align="center"><a href="t3.pdf">T3</a></div></td>
  </tr>
  <tr class="holiday">
     <th scope="row">9 (Oct2-Oct6)</th>
    <td>Exam Week <a href="mid.pdf">Mid-Sem</a> <a href="mid-sol.pdf">Mid-Sem-Sol</a><br />
    </td>
    <td><div align="center"></div></td>
  </tr>
  <tr>
    <th scope="row">10 (Oct9-Oct13)</th>
    <td><a href="w10.pdf">Bayesian Learning</a><br />
   		Readings:
        <ul>
        <li> Chapter 6 (ML)</li>
        </ul>
    	Other Reference Material: <br />
        Scribes: Aditya Gupta, Mandhatya Singh, N Nikhil, Sagarika Sharma	 	
    </td>
    <td><div align="center"><a href="t4.pdf">T4</a></div></td>
  </tr>
  <tr>
   <th scope="row">11 (Oct16-Oct20)</th>
    <td><a href="w11.pdf">Hidden Markov Models</a><br />
   		Readings:
        <ul>
        <li> <a href="rabiner.pdf">Tutorial Paper on HMM by Rabiner, 1999</a> (until Page 266) </li>
        </ul>
    	Other Reference Material:
        <ul>
        <li> Chapter 13.1-13.2 (PRML) </li>
        </ul>
        Scribes: Piyush Jain, Shubham Dham, Sonu, Unit Bhupendra Patel	 	
    </td>
    <td><div align="center"><a href="t5.pdf">T5</a></div></td>
  </tr>
  <tr>
    <th scope="row">12 (Oct23-Oct27)</th>
    <td rowspan="2"><a href="w12-13.pdf">Kernel Methods</a><br />
   		Readings:
        <ul>
        <li> Chapter 13 (IML)</li>
        <li> <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf">Notes</a> by Andrew Ng</li>
        <li> <a href="smo-original.pdf">SMO</a> by Platt </li>
        </ul>
    	Other Reference Material: 
        <ul>
        <li>Lagrange Multipliers Appendix E (PRML)</li>
        <li>Lectures 12.1-12.6 of Andrew Ng on coursera (to get a quick overview)</li>
        <li><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LibSVM</a> - popular SVM toolbox</li>
        </ul>
        Scribes: (week 12) Keshav Garg, Pankaj Verma, Prateek Munjal, Shivam Mittal <br />
        Scribes: (week 13) Pratik Chhajer, Manas Gupta, Soumyadeep Roy	 	
    </td>
    <td><div align="center"><a href="q3.pdf">Q3</a></div></td>
  </tr>
  <tr>
    <th scope="row">13 (Oct30-Nov3)</th>
    <td><div align="center"><a href="l3.zip">L3 (Nov <s>3</s>6)</a></div></td>
  </tr>
  <tr>
     <th scope="row">14 (Nov6-Nov10)</th>
    <td><a href="w14.pdf">Clustering</a><br />
   		Readings:
        <ul>
        <li> Chapter 14 - 14.3 (ESL) (for k-Means, Hierarchical Clustering)</li>
        <li> Chapter 9 - 9.1-9.2 (PRML) (for Gaussian Mixture Models)</li>
        </ul>
    	Other Reference Material: 
        <ul>
        <li> <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.9220">DBSCAN</a> </li>
        </ul>
        Scribes: Ankit Kumar Meena, Bishal Gosh, Naman Goyal, Shikar Jaiswal	 	
    </td>
    <td><div align="center"><a href="t6.pdf">T6</a></div></td>
  </tr>
  <tr>
     <th scope="row">15 (Nov13-Nov17)</th>
    <td><a href="w15.pdf">Dimensionality Reduction</a><br />
   		Readings:
        <ul>
        <li> Chapter 14.5 (ESL) (Principal Component Analysis)</li>
        <li> Chapter 12.1 (PRML)</li>
        <li> <a href="kernelPCA_scholkopf.pdf">Kernel PCA (original paper)</a></li>
        <li> Chapter 6.6 (IML) (LDA)</li>
        </ul>
    	Other Reference Material: 
    	<ul>
        	<li><a href="http://www.ics.uci.edu/~welling/classnotes/papers_class/Kernel-PCA.pdf">Kernel PCA (notes)</a></li>
            <li>LDA - Chapter  5.7-5.8 - Pattern Classification by Duda, Hart and Stork</li>
            <li>Non-linear dimensionality reduction <a href="http://web.mit.edu/cocosci/isomap/isomap.html">ISOMAP</a></li>
        </ul>
    	  Scribes: Himanshu Dahiya, Krishan Dev, SD Mahanoor, Sumit Singh	 	
  	  </p></td>
    <td><div align="center"><a href="q4.pdf">Q4</a></div></td>
  </tr>
  <tr>
    <th scope="row">16 (Nov20-Nov24)</th>
    <td><a href="w16.pdf">Reserve Week</a><br />
   		Readings: <br />
    	Other Reference Material: <br />
        Scribes: Abhash yadav, Abhishek Chowdhry, Manish Singh</td>
    <td><div align="center"><a href="l4.zip">L4 (Nov 24)</a></div></td>
  </tr>
  <tr class="holiday">
   <th scope="row">17 (Nov27-Dec1)</th>
    <td>Exam Week <a href="end.pdf">End-Sem</a> <a href="end-sol.pdf">End-Sem-Sol</a></td>
    <td><div align="center"></div></td>
  </tr>
 
</table>
</div>
<p>*This is a tentative list of topics that will be covered during the semester. The topics and schedule can change according to the need at the discretion of the instructor. </p>
<p>ML - Machine Learning</p>
<p>PRML - Pattern Recognition and Machine Learning</p>
<p>IML - Introduction to Machine Learning</p>
<p> ESL - Elements of Statistical Learning</p>
<div align="right"> 
  <a href="#top">Scroll to top </a>
  <hr width="50%" />
</div>
</section>

<a name="labs"></a>
<section title="Labs">
<h2 align="left"> Labs </h2>
<ul>
  <li><a href="l1.pdf">Sentiment classification of movie reviews using decision trees and forests</a> due 11.55pm Monday September 4th 2017</li>
  <li><a href="l2.zip">Regularized Linear and Logistic Regression</a> due 11.55pm Friday September 22nd 2017</li>
  <li><a href="l3.zip">Multi-layer perceptrons and Self Driving Cars</a> due 11.55pm <s>Friday November 3rd</s> Monday November 6th 2017 <a href="l3-test.zip">Test Data</a></li> 
  <li><a href="l4.zip">K-means clustering, Principal Component Analysis and MNIST</a> due 11.55pn Friday November 24th, 2017</li>
</ul>
<p align="left">&nbsp;</p>
<div align="right"> 
  <a href="#top">Scroll to top </a>
  <hr width="50%" />
</div>
</section>

</div>

<div id="footer">
<p>Narayanan (CK) Chatapuram Krishnan - ckn@iitrpr.ac.in - Indian Institute of Technology Ropar</p>
</div>

</html>
